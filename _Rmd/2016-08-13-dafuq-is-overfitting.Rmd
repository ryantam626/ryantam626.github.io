---
layout: post
title:  "Dafuq Is Overfitting? [DRAFT]"
date:   2016-08-13
category:
  - Machine Learning
tags:
  - Dafuq
  - Terminology

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Overfitting, a term to discribe the situation where a model describes random error/noise in the data on top of modelling the underlying relationship within the data. 

Model that has been overfitted usually has a poor predictive performance on new unseen data, because if the error/noise is truly random, chances are that you are never going to get exactly the same instances as the training data.

## Example

We now dive into a bit of R code to have see the effects of overfitting in a very simple example.

We first load the library for plotting:-

```{r load.lib}
library(ggplot2)
```

The problem is to find a function to model $$\sin{x}$$ with some additive white noise (Gaussian) in the range of $$(-3.2, 3.2)$$, we generate some data of the underlying function $$(\sin{x})$$ for plotting first:-

```{r sin}
sin.x <- seq(-3.2,3.2,0.05)
sin.y <- sin(sin.x)
sin.df <- data.frame(x=sin.x, y=sin.y)
```

Then we produce some data for trianing:-
```{r gen.train}
generate_train_data <- function(size){
  x <- seq(-3.2, 3.2, 6.4/size) # get a range of x
  y <- sin(x) + rnorm(length(x), 0, sqrt(0.04)) # simulate the corresponding y with error
  return(data.frame(x=x,y=y))
}

set.seed(888)
train.df <- generate_train_data(9)
```

We first fit a linear equation to fit the function:-
```{r linear.model}
linear.model <- lm(y ~ x, data=train.df)
linear.model.pred <- predict(linear.model, sin.df)
linear.model.pred.df <- data.frame(x=sin.df$x, y=linear.model.pred, order=1)
```

The residual sum of squares (RSS) is,
``` {r linear.model.rss}
sum(linear.model$residuals^2)
```

Then fit a third, sixth and nineth order equation similarly:-
``` {r higher.model}
third.order.model <- lm(y ~ poly(x, 3, raw=TRUE), data=train.df)
third.order.model.pred <- predict(third.order.model, sin.df)
third.order.model.pred.df <- data.frame(x=sin.df$x, y=third.order.model.pred, order=3)

sixth.order.model <- lm(y ~ poly(x, 6, raw=TRUE), data=train.df)
sixth.order.model.pred <- predict(sixth.order.model, sin.df)
sixth.order.model.pred.df <- data.frame(x=sin.df$x, y=sixth.order.model.pred, order=6)

nineth.order.model <- lm(y ~ poly(x, 9, raw=TRUE), data=train.df)
nineth.order.model.pred <- predict(nineth.order.model, sin.df)
nineth.order.model.pred.df <- data.frame(x=sin.df$x, y=nineth.order.model.pred, order=9)
```

The RSS for them respectively are:-
``` {r higher.model.rss}
sum(third.order.model$residuals^2)
sum(sixth.order.model$residuals^2)
sum(nineth.order.model$residuals^2)
```


The overlayed plot of all these models together is:-
``` {r plot.all}
everything <- rbind(linear.model.pred.df, third.order.model.pred.df,
                    sixth.order.model.pred.df, nineth.order.model.pred.df)
everything$order <- as.factor(everything$order)
ggplot() + geom_line(data=sin.df, aes(x=x, y=y)) +
  geom_line(data=everything, aes(x=x, y=y, colour=order)) + 
  geom_point(data=train.df, aes(x=x, y=y), colour='red') 
```

The effects of overfitting is apparent here, the nineth ordered equation passes through all the training data and has achieved a RSS of $$0$$, in doing so it also captured the random errors and has failed spectacularly in generalising to unseen data.

On the other end of the spectrum, we have the linear model, it has also failed to model the underlying function due to the lack of complexity in the model, also known as underfitting. 

## Detecting Overfit

In this polynomail regression problem, visualisation of the model is straight forward, and overfitting can be spotted visually. What if the model is something more complicated like a **decision tree** or **nerual network**? These models can't be visualised easily, so how might one go about detecting overfit with such models?

As mentioned before, overfitted models has poor predictive performance on new unseen data; from this, we can spot effects of overfitting by comparing the training error and test error accross different models.

``` {r detect.overfit, echo=FALSE}
set.seed(888)
train.df <- generate_train_data(9)

set.seed(1234)
test.df <- generate_train_data(100)

pp <- c()
train.rss.list <- c()
test.rss.list <- c()
for(iter in seq(1,9)){
  trained.model <- lm(y~ poly(x,iter, raw=TRUE), data=train.df)
  train.rss <- sum(trained.model$residuals^2)
  trained.model.pred <- predict(trained.model, test.df)
  test.rss <- sum((test.df$y - trained.model.pred)^2)
  test.rss.list <- c(test.rss, test.rss.list)
  train.rss.list <- c(train.rss, train.rss.list)
  pp <- c(iter ,pp)
}

met.df <- data.frame(order=pp, test_rss=test.rss.list, train_rss=train.rss.list)

ggplot() + geom_line(data=met.df, aes(x=order, y=-train_rss, colour='Train')) + 
	geom_line(data=met.df, aes(x=order, y=-test_rss, colour='Test')) + ylab('Negative RSS') + xlab('Order') + 
  scale_x_continuous(breaks = seq(0,9)) + scale_colour_manual("", 
                      breaks = c("Train", "Test"),
                      values = c("red", "green")) + ggtitle("Performance of Polynomial Regression")
```

Here, negative RSS can be thought of as an analogy of accuracy, the higher it is the better. We note that the negative RSS goes up as order goes up for the training data, similar trend cannot be established for the test data, and this implies overfit!

## Dealing with Overfit

One "easy" way to deal overfitting is to obtain more data, in the polynomial regression above, if we obtained more training data, models with enough complexity looks roughly like the underlying function:-

``` {r more.data, echo=FALSE}
set.seed(888)
train.df <- generate_train_data(200)
linear.model <- lm(y ~ x, data=train.df)
linear.model.pred <- predict(linear.model, sin.df)
linear.model.pred.df <- data.frame(x=sin.df$x, y=linear.model.pred, order=1)
third.order.model <- lm(y ~ poly(x, 3, raw=TRUE), data=train.df)
third.order.model.pred <- predict(third.order.model, sin.df)
third.order.model.pred.df <- data.frame(x=sin.df$x, y=third.order.model.pred, order=3)

sixth.order.model <- lm(y ~ poly(x, 6, raw=TRUE), data=train.df)
sixth.order.model.pred <- predict(sixth.order.model, sin.df)
sixth.order.model.pred.df <- data.frame(x=sin.df$x, y=sixth.order.model.pred, order=6)

nineth.order.model <- lm(y ~ poly(x, 9, raw=TRUE), data=train.df)
nineth.order.model.pred <- predict(nineth.order.model, sin.df)
nineth.order.model.pred.df <- data.frame(x=sin.df$x, y=nineth.order.model.pred, order=9)

everything <- rbind(linear.model.pred.df, third.order.model.pred.df, sixth.order.model.pred.df, nineth.order.model.pred.df)
everything$order <- as.factor(everything$order)
ggplot() + geom_line(data=sin.df, aes(x=x, y=y)) + 
	geom_line(data=everything, aes(x=x, y=y, colour=order)) +
	geom_point(data=train.df, aes(x=x, y=y), colour='red') 
```



